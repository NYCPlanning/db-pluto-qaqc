{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.82.70.250:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. read in file: \n",
    "```\n",
    "bike = sc.textFile('citibike.csv')\n",
    "\n",
    "```\n",
    "#### 2. look at column names: \n",
    "```\n",
    "list(enumerate(bike.first().split(',')))\n",
    "\n",
    "```\n",
    "#### 3. set up generator function: \n",
    "```\n",
    "def bikeFilter(records):\n",
    "    for record in records: \n",
    "        fields = record.split(',')\n",
    "        if (fields[6] =='Greenwich Ave & 8 Ave' and\n",
    "                fields[3].startswith('2015-02-01')):\n",
    "            yield fields[3]\n",
    "\n",
    "matchedBike = bike.mapPartitions(bikeFilter)\n",
    "```\n",
    "#### 4. retrieve results: \n",
    "```\n",
    "matchedBike.take(2)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import glob\n",
    "import subprocess\n",
    "import csv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd18 = sc.textFile('test_data/18v1.csv')\n",
    "rdd17 = sc.textFile('test_data/17v1.csv')\n",
    "colnames18 = list(rdd18.first().split(','))\n",
    "colnames17 = list(rdd17.first().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames18 == colnames17 #they have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_over(pid, record):\n",
    "    import csv    \n",
    "    if pid ==0:\n",
    "        next(record)\n",
    "    reader = csv.reader(record)\n",
    "    \n",
    "    def check_null(string):\n",
    "        try:\n",
    "            return float(string)\n",
    "        except: \n",
    "            return 0\n",
    "    for row in reader:\n",
    "        target46 = float(row[46]) \n",
    "        target33 = float(row[33]) \n",
    "        target34 = float(row[34]) \n",
    "        target35 = float(row[35]) \n",
    "        target36 = float(row[36]) \n",
    "        target37 = float(row[37]) \n",
    "        target38 = float(row[38]) \n",
    "        target39 = float(row[39]) \n",
    "        target40 = float(row[40]) \n",
    "        target41 = float(row[41]) \n",
    "        target42 = float(row[42]) \n",
    "        target57 = float(row[57]) \n",
    "        target58 = float(row[58]) \n",
    "        target59 = float(row[59]) \n",
    "        target60 = float(row[60]) \n",
    "        target84 = check_null(row[84]) \n",
    "        target85 = check_null(row[85])\n",
    "        LotAreaXBuiltFAR = float(row[33])*float(row[66])\n",
    "        LotAreaXResidFAR = float(row[33])*float(row[67])\n",
    "        LotAreaXCommFAR = float(row[33])*float(row[68])\n",
    "        LotAreaXFacilFAR = float(row[33])*float(row[69])\n",
    "        yield(1, np.array([target46, target33, target34, \n",
    "                           target35, target36, target37, \n",
    "                           target38, target39, target40, \n",
    "                           target41, target42, target57, \n",
    "                           target58, target59, target60, \n",
    "                           target84, target85, LotAreaXBuiltFAR,\n",
    "                           LotAreaXResidFAR, LotAreaXCommFAR,LotAreaXFacilFAR]))\n",
    "        \n",
    "sum_total = rdd18.mapPartitionsWithIndex(sum_over)\\\n",
    "               .reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sum_total.collect()\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.55587100e+06, 6.81580562e+09, 5.48476476e+09, 1.81628405e+09,\n",
       "       3.47020402e+09, 6.52968426e+08, 2.76388698e+08, 1.22406091e+08,\n",
       "       1.02263027e+08, 1.16348116e+08, 5.24094223e+08, 9.77991789e+10,\n",
       "       3.95591820e+11, 4.41422674e+10, 1.42207701e+11, 3.45620000e+04,\n",
       "       6.56180000e+04, 5.44844134e+09, 6.73310388e+09, 2.86501091e+09,\n",
       "       1.21944385e+10])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_total.collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['18v1', '17v1_1', '17v1', '16v2']\n",
    "\n",
    "# key indicators we need in the following: \n",
    "sum_targets =['UnitsRes',\n",
    " 'LotArea',\n",
    " 'BldgArea',\n",
    " 'ComArea',\n",
    " 'ResArea',\n",
    " 'OfficeArea',\n",
    " 'RetailArea',\n",
    " 'GarageArea',\n",
    " 'StrgeArea',\n",
    " 'FactryArea',\n",
    " 'OtherArea',\n",
    " 'AssessLand',\n",
    " 'AssessTot',\n",
    " 'ExemptLand',\n",
    " 'ExemptTot',\n",
    " 'FIRM07_FLAG',\n",
    " 'PFIRM15_FLAG']\n",
    "\n",
    "sumproduct_targets = ['LotAreaXBuiltFAR', 'LotAreaXResidFAR',\n",
    "                     'LotAreaXCommFAR', 'LotAreaXFacilFAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [colnames17.index(i) for i in sum_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames17.index('FacilFAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NotImplemented"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.equal(['a'], ['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.core.defchararray.equal(['', '2'], ['1', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('test_data/18v1.csv') as f1, open('test_data/17v1.csv') as f2:\n",
    "    r1 = csv.reader(f1)\n",
    "    r2 = csv.reader(f2)\n",
    "    st = set((row[0], row[2]) for row in r1)\n",
    "    for row in r2:\n",
    "        if tuple(row) in st:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.82.70.250:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
