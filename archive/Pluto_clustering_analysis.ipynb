{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data.\n",
    "df = spark.read.csv('data/pluto.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lotarea',\n",
    " 'bldgarea',\n",
    " 'comarea',\n",
    " 'resarea',\n",
    " 'officearea',\n",
    " 'retailarea',\n",
    " 'garagearea',\n",
    " 'strgearea',\n",
    " 'factryarea',\n",
    " 'otherarea',\n",
    " 'areasource',\n",
    " 'numbldgs',\n",
    " 'numfloors',\n",
    " 'unitsres',\n",
    " 'unitstotal',\n",
    " 'lotfront',\n",
    " 'lotdepth',\n",
    " 'bldgfront',\n",
    " 'bldgdepth',\n",
    " 'assessland',\n",
    " 'assesstot',\n",
    " 'exemptland',\n",
    " 'exempttot',\n",
    " 'yearbuilt',\n",
    " 'builtfar',\n",
    " 'residfar',\n",
    " 'commfar',\n",
    " 'facilfar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([col(A).cast(DoubleType()) for A in cols])\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "new_df = vecAssembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with 2 clusters = 0.9999891613792797\n",
      "Silhouette with 3 clusters = 0.9997347484586968\n",
      "Silhouette with 4 clusters = 0.9997347891466806\n",
      "Silhouette with 5 clusters = 0.9978423180139647\n",
      "Silhouette with 6 clusters = 0.9977768216857009\n",
      "Silhouette with 7 clusters = 0.9979956260911077\n",
      "Silhouette with 8 clusters = 0.9978777742031587\n",
      "Silhouette with 9 clusters = 0.9977512949654372\n",
      "Silhouette with 10 clusters = 0.9972133246990466\n",
      "Silhouette with 11 clusters = 0.9930501731287215\n",
      "Silhouette with 12 clusters = 0.9953466402936372\n",
      "Silhouette with 13 clusters = 0.9953480171720165\n",
      "Silhouette with 14 clusters = 0.9935756886033832\n",
      "Silhouette with 15 clusters = 0.9937739691710925\n",
      "Silhouette with 16 clusters = 0.9896525707538683\n",
      "Silhouette with 17 clusters = 0.9910882997615047\n",
      "Silhouette with 18 clusters = 0.9899316095034388\n",
      "Silhouette with 19 clusters = 0.9832976786616847\n"
     ]
    }
   ],
   "source": [
    "# Trains a k-means model.\n",
    "silhuette_scores = []\n",
    "for i in range(2, 20):\n",
    "    kmeans = KMeans(k=i, seed=1)  # 2 clusters here\n",
    "    model = kmeans.fit(new_df.select('features'))\n",
    "    transformed = model.transform(new_df)\n",
    "    evaluator = ClusteringEvaluator()\n",
    "    silhouette = evaluator.evaluate(transformed)\n",
    "    silhuette_scores.append(silhouette)\n",
    "    print(\"Silhouette with {} clusters = \".format(i) + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA as PCAml\n",
    "pca = PCAml(k=len(cols), inputCol=\"features\", outputCol=\"pca\")\n",
    "model = pca.fit(new_df.select('features'))\n",
    "transformed1 = model.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "dfn = normalizer.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+-------+----------+----------+----------+---------+----------+---------+----------+--------+---------+--------+----------+--------+--------+---------+---------+----------+---------+----------+---------+---------+--------+--------+-------+--------+--------------------+--------------------+\n",
      "|lotarea|bldgarea|comarea|resarea|officearea|retailarea|garagearea|strgearea|factryarea|otherarea|areasource|numbldgs|numfloors|unitsres|unitstotal|lotfront|lotdepth|bldgfront|bldgdepth|assessland|assesstot|exemptland|exempttot|yearbuilt|builtfar|residfar|commfar|facilfar|            features|        normFeatures|\n",
      "+-------+--------+-------+-------+----------+----------+----------+---------+----------+---------+----------+--------+---------+--------+----------+--------+--------+---------+---------+----------+---------+----------+---------+---------+--------+--------+-------+--------+--------------------+--------------------+\n",
      "| 9750.0|  1000.0|    0.0| 1000.0|       0.0|       0.0|       0.0|      0.0|       0.0|      0.0|       2.0|     1.0|      1.0|     1.0|       1.0|    65.0|   150.0|     25.0|     33.0|   14367.0|  27368.0|    2960.0|   5000.0|   1955.0|     0.1|     0.6|    0.0|     1.0|[9750.0,1000.0,0....|[0.15310761345274...|\n",
      "|  600.0|     0.0|    0.0|    0.0|       0.0|       0.0|       0.0|      0.0|       0.0|      0.0|       7.0|     0.0|      0.0|     0.0|       0.0|    6.25|   100.0|      0.0|      0.0|     348.0|    348.0|       0.0|      0.0|      0.0|     0.0|     0.6|    0.0|     1.0|(28,[0,10,15,16,1...|(28,[0,10,15,16,1...|\n",
      "| 2500.0|  6524.0|    0.0| 6524.0|       0.0|       0.0|       0.0|      0.0|       0.0|      0.0|       2.0|     1.0|      4.0|     8.0|       8.0|    25.0|   100.0|     25.0|     70.0|    1311.0| 100395.0|       0.0|      0.0|   1925.0|    2.61|     2.0|    0.0|     2.0|[2500.0,6524.0,0....|[0.02093300759340...|\n",
      "| 1667.0|  2112.0|    0.0| 2112.0|       0.0|       0.0|       0.0|      0.0|       0.0|      0.0|       2.0|     1.0|      3.0|     3.0|       3.0|   16.67|   100.0|    16.67|     50.0|    3282.0|   6805.0|       0.0|      0.0|   1901.0|    1.27|    2.43|    0.0|     4.8|[1667.0,2112.0,0....|[0.09218684675637...|\n",
      "| 2500.0|  3750.0|    0.0| 3750.0|       0.0|       0.0|       0.0|      0.0|       0.0|      0.0|       2.0|     1.0|      3.0|     6.0|       6.0|    25.0|   100.0|     25.0|     50.0|     601.0|  56448.0|       0.0|      0.0|   1910.0|     1.5|     2.0|    0.0|     2.0|[2500.0,3750.0,0....|[0.03613630614678...|\n",
      "+-------+--------+-------+-------+----------+----------+----------+---------+----------+---------+----------+--------+---------+--------+----------+--------+--------+---------+---------+----------+---------+----------+---------+---------+--------+--------+-------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfn.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
